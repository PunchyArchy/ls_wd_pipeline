import os
import json
import argparse
from collections import Counter
from sklearn.model_selection import train_test_split
from ls_wb_pipeline import functions
import shutil

# ==== –ù–ê–°–¢–†–û–ô–ö–ò (–º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –≤–Ω—É—Ç—Ä–∏ —Å–∫—Ä–∏–ø—Ç–∞) ====
SOURCE_IMAGE_DIR = functions.MOUNTED_PATH
OUTPUT_DIR = "./dataset_yolo"
SPLIT_RATIO = (0.8, 0.1, 0.1)  # train, val, test

def main(json_path):
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    entries = []
    class_names = set()

    for task in data:
        anns = task.get("annotations")
        if not anns or not isinstance(anns, list):
            continue
        first_ann = anns[0]
        results = first_ann.get("result", [])
        if not results:
            continue
        try:
            class_name = results[0]["value"]["choices"][0]
            image_url = task["data"]["image"]
            image_name = os.path.basename(image_url)
            class_names.add(class_name)
            entries.append({
                "image": image_name,
                "class": class_name
            })
        except Exception:
            continue

    if not entries:
        print("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á.")
        return

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤
    class_list = sorted(class_names)
    class_to_index = {name: i for i, name in enumerate(class_list)}

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫
    splits = ["train", "val", "test"]
    for split in splits:
        os.makedirs(os.path.join(OUTPUT_DIR, "images", split), exist_ok=True)
        os.makedirs(os.path.join(OUTPUT_DIR, "labels", split), exist_ok=True)

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val/test
    train_val, test = train_test_split(entries, test_size=SPLIT_RATIO[2], random_state=42)
    train, val = train_test_split(train_val, test_size=SPLIT_RATIO[1]/(SPLIT_RATIO[0]+SPLIT_RATIO[1]), random_state=42)
    split_data = {"train": train, "val": val, "test": test}

    # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è .txt –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    for split, items in split_data.items():
        for item in items:
            image_name = item["image"]
            class_id = class_to_index[item["class"]]
            label_file = os.path.join(OUTPUT_DIR, "labels", split, image_name.replace(".jpg", ".txt"))
            image_src = os.path.join(SOURCE_IMAGE_DIR, image_name)
            image_dst = os.path.join(OUTPUT_DIR, "images", split, image_name)

            # –ø–∏—à–µ–º –∫–ª–∞—Å—Å –≤ YOLO-—Ñ–æ—Ä–º–∞—Ç–µ
            with open(label_file, "w") as f:
                f.write(f"{class_id}\n")

            # –∫–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if os.path.exists(image_src):
                shutil.copy(image_src, image_dst)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º classes.txt
    with open(os.path.join(OUTPUT_DIR, "classes.txt"), "w") as f:
        for name in class_list:
            f.write(f"{name}\n")

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
    summary = Counter(e["class"] for e in entries)
    print(f"\n–î–∞—Ç–∞—Å–µ—Ç —Å–æ–±—Ä–∞–Ω. {OUTPUT_DIR}")
    total = sum(summary.values())
    print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
    for cls in class_list:
        count = summary[cls]
        percent = (count / total) * 100
        print(f"{cls:25} ‚Äî {count:3} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({percent:.1f}%)")

    print("\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    avg = total / len(class_list)
    for cls in class_list:
        diff = summary[cls] - avg
        if diff < -10:
            print(f"–ö–ª–∞—Å—Å—É '{cls}' –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ {int(-diff)} –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞.")
        elif diff > 10:
            print(f"–ö–ª–∞—Å—Å–∞ '{cls}' –∑–∞–º–µ—Ç–Ω–æ –±–æ–ª—å—à–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö (–Ω–∞ +{int(diff)}).")

def analyze_full_dataset(dataset_path=OUTPUT_DIR):
    labels_root = os.path.join(dataset_path, "labels")
    classes_file = os.path.join(dataset_path, "classes.txt")

    if not os.path.exists(labels_root) or not os.path.exists(classes_file):
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω labels/ –∏–ª–∏ classes.txt ‚Äî –¥–∞—Ç–∞—Å–µ—Ç –µ—â—ë –Ω–µ —Å–æ–∑–¥–∞–Ω?")
        return

    # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤
    with open(classes_file, "r", encoding="utf-8") as f:
        classes = [line.strip() for line in f if line.strip()]

    counter = Counter()
    for split in ("train", "val", "test"):
        label_dir = os.path.join(labels_root, split)
        if not os.path.exists(label_dir):
            continue
        for fname in os.listdir(label_dir):
            if fname.endswith(".txt"):
                fpath = os.path.join(label_dir, fname)
                with open(fpath, "r", encoding="utf-8") as f:
                    line = f.readline().strip()
                    if line.isdigit():
                        class_id = int(line)
                        counter[class_id] += 1

    total = sum(counter.values())
    print("\nüì¶ –û–±—â–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ –ø–æ –≤—Å–µ–º —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–º –∫–ª–∞—Å—Å–∞–º:")
    avg = total / len(classes)

    for class_id, name in enumerate(classes):
        count = counter[class_id]
        percent = (count / total) * 100 if total else 0
        print(f"{class_id}: {name:25} ‚Äî {count:3} —à—Ç. ({percent:.1f}%)", end="")
        if count < avg - 10:
            print("   ‚ö†Ô∏è –ú–∞–ª–æ –ø—Ä–∏–º–µ—Ä–æ–≤")
        elif count > avg + 10:
            print("   ‚ÑπÔ∏è –ü—Ä–µ–≤—ã—à–∞–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ")
        else:
            print("")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–°–±–æ—Ä–∫–∞ YOLO –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ Label Studio JSON")
    parser.add_argument("--json", required=True, help="–ü—É—Ç—å –¥–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ JSON-—Ñ–∞–π–ª–∞ –∏–∑ Label Studio")
    args = parser.parse_args()
    main(args.json)

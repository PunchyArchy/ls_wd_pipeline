import os
import json
import argparse
from collections import Counter
from urllib.parse import unquote
from sklearn.model_selection import train_test_split
from ls_wb_pipeline import functions
import shutil

# ==== –ù–ê–°–¢–†–û–ô–ö–ò (–º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –≤–Ω—É—Ç—Ä–∏ —Å–∫—Ä–∏–ø—Ç–∞) ====
SOURCE_IMAGE_DIR = functions.MOUNTED_PATH
OUTPUT_DIR = "./dataset_yolo"
SPLIT_RATIO = (0.8, 0.1, 0.1)  # train, val, test

def main(json_path):
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
    existing_images = set()
    for split in ("train", "val", "test"):
        img_dir = os.path.join(OUTPUT_DIR, "images", split)
        if os.path.exists(img_dir):
            for fname in os.listdir(img_dir):
                if fname.lower().endswith(".jpg"):
                    existing_images.add(fname)

    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    entries = []
    class_names = set()

    for task in data:
        anns = task.get("annotations")
        if not anns or not isinstance(anns, list):
            continue
        first_ann = anns[0]
        results = first_ann.get("result", [])
        if not results:
            continue
        try:
            class_name = results[0]["value"]["choices"][0]
            image_url = task["data"]["image"]
            image_name = os.path.basename(unquote(image_url))
            if image_name in existing_images:
                continue  # ‚ùóÔ∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ
            class_names.add(class_name)
            entries.append({
                "image": image_name,
                "class": class_name
            })
        except Exception:
            continue

    if not entries:
        print("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á.")
        return

    # –ó–∞–≥—Ä—É–∑–∫–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–ª–∞—Å—Å–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    existing_classes = []
    classes_path = os.path.join(OUTPUT_DIR, "classes.txt")

    if os.path.exists(classes_path):
        with open(classes_path, "r", encoding="utf-8") as f:
            existing_classes = [line.strip() for line in f if line.strip()]

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç–∞—Ä—ã–µ –∏ –Ω–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã, —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏
    all_classes = list(dict.fromkeys(existing_classes + sorted(class_names)))  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫

    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ OUTPUT_DIR —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
    with open(classes_path, "w", encoding="utf-8") as f:
        for name in all_classes:
            f.write(f"{name}\n")

    # ‚úÖ –°–æ–∑–¥–∞—ë–º class_to_index –Ω–∞ –æ—Å–Ω–æ–≤–µ all_classes
    class_to_index = {name: i for i, name in enumerate(all_classes)}

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫
    splits = ["train", "val", "test"]
    for split in splits:
        os.makedirs(os.path.join(OUTPUT_DIR, "images", split), exist_ok=True)
        os.makedirs(os.path.join(OUTPUT_DIR, "labels", split), exist_ok=True)

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val/test
    if len(entries) < 3:
        split_data = {"train": entries, "val": [], "test": []}
    else:
        train_val, test = train_test_split(entries, test_size=SPLIT_RATIO[2], random_state=42)
        train, val = train_test_split(train_val, test_size=SPLIT_RATIO[1]/(SPLIT_RATIO[0]+SPLIT_RATIO[1]), random_state=42)
        split_data = {"train": train, "val": val, "test": test}


    # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è .txt –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    for split, items in split_data.items():
        for item in items:
            image_name = item["image"]
            class_id = class_to_index[item["class"]]
            label_file = os.path.join(OUTPUT_DIR, "labels", split, image_name.replace(".jpg", ".txt"))
            image_src = os.path.join(SOURCE_IMAGE_DIR, image_name)
            image_dst = os.path.join(OUTPUT_DIR, "images", split, image_name)

            # –ø–∏—à–µ–º –∫–ª–∞—Å—Å –≤ YOLO-—Ñ–æ—Ä–º–∞—Ç–µ
            with open(label_file, "w") as f:
                f.write(f"{class_id}\n")

            # –∫–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if os.path.exists(image_src):
                shutil.copy(image_src, image_dst)

    # –ù–æ–≤—ã–π summary –ø–æ –∏–Ω–¥–µ–∫—Å—É –∫–ª–∞—Å—Å–æ–≤
    summary = Counter(class_to_index[e["class"]] for e in entries)

    print(f"\n–î–∞—Ç–∞—Å–µ—Ç —Å–æ–±—Ä–∞–Ω. {OUTPUT_DIR}")
    total = sum(summary.values())
    print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ –∑–∞–¥–∞–Ω–Ω–æ–º JSON:")
    for class_id, class_name in enumerate(all_classes):
        count = summary[class_id]
        percent = (count / total) * 100 if total else 0
        print(f"{class_name:25} ‚Äî {count:3} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({percent:.1f}%)")


def analyze_full_dataset(dataset_path=OUTPUT_DIR):
    labels_root = os.path.join(dataset_path, "labels")
    classes_file = os.path.join(dataset_path, "classes.txt")

    if not os.path.exists(labels_root) or not os.path.exists(classes_file):
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω labels/ –∏–ª–∏ classes.txt ‚Äî –¥–∞—Ç–∞—Å–µ—Ç –µ—â—ë –Ω–µ —Å–æ–∑–¥–∞–Ω?")
        return

    # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤
    with open(classes_file, "r", encoding="utf-8") as f:
        classes = [line.strip() for line in f if line.strip()]

    # –°—á—ë—Ç—á–∏–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É —Å–ø–ª–∏—Ç—É
    split_counters = {
        "train": Counter(),
        "val": Counter(),
        "test": Counter()
    }

    for split in split_counters:
        label_dir = os.path.join(labels_root, split)
        if not os.path.exists(label_dir):
            continue
        for fname in os.listdir(label_dir):
            if fname.endswith(".txt"):
                fpath = os.path.join(label_dir, fname)
                with open(fpath, "r", encoding="utf-8") as f:
                    line = f.readline().strip()
                    if line.isdigit():
                        class_id = int(line)
                        split_counters[split][class_id] += 1

    total = sum(sum(c.values()) for c in split_counters.values())
    print("\nüì¶ –û–±—â–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ –ø–æ –≤—Å–µ–º —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–º –∫–ª–∞—Å—Å–∞–º (–≤—Å–µ–≥–æ: {}):".format(total))
    avg = total / len(classes) if classes else 0

    print(f"{'ID':<3} {'–ö–ª–∞—Å—Å':<25} {'Train':>6} {'Val':>6} {'Test':>6} {'Total':>6} {'%':>6}")
    print("-" * 60)
    for class_id, class_name in enumerate(classes):
        tr = split_counters["train"][class_id]
        va = split_counters["val"][class_id]
        te = split_counters["test"][class_id]
        total_cls = tr + va + te
        percent = (total_cls / total) * 100 if total else 0
        print(f"{class_id:<3} {class_name:<25} {tr:6} {va:6} {te:6} {total_cls:6} {percent:5.1f}%")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–°–±–æ—Ä–∫–∞ YOLO –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ Label Studio JSON")
    parser.add_argument("--json", required=True, help="–ü—É—Ç—å –¥–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ JSON-—Ñ–∞–π–ª–∞ –∏–∑ Label Studio")
    args = parser.parse_args()
    main(args.json)
